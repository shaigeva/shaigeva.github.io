<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Shai Geva</title>
    <link>https://shaigeva.com/posts/</link>
    <description>Recent content in Posts on Shai Geva</description>
    <generator>Hugo -- 0.134.3</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Oct 2024 20:15:56 +0300</lastBuildDate>
    <atom:link href="https://shaigeva.com/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>10 Ways To Shoot Yourself In The Foot With Tests</title>
      <link>https://shaigeva.com/posts/10_footguns/ten_footguns/</link>
      <pubDate>Fri, 04 Oct 2024 13:01:56 +0300</pubDate>
      <guid>https://shaigeva.com/posts/10_footguns/ten_footguns/</guid>
      <description>&lt;p&gt;This is a series of posts, following a talk I gave (twice - at Pycon-US 2023 and Pycon-IL 2024), about testing best (and not-so-best) practices.&lt;/p&gt;
&lt;p&gt;The talk shares 10 practices that I had bad experience with, along with ways of avoiding them.&lt;/p&gt;
&lt;p&gt;Starting with simple (but useful!), and moving on to more complex ideas:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://shaigeva.com/posts/10_footguns/01_there_are_no_tests/&#34;&gt;There are no tests&lt;/a&gt; (warm up)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://shaigeva.com/posts/10_footguns/02_untested_tests/&#34;&gt;Untested tests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://shaigeva.com/posts/10_footguns/03_the_tests_are_not_isolated/&#34;&gt;The tests are not isolated&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;No locality of behavior&lt;/li&gt;
&lt;li&gt;Unclear language&lt;/li&gt;
&lt;li&gt;Testing too many things&lt;/li&gt;
&lt;li&gt;Improper test scope&lt;/li&gt;
&lt;li&gt;Test doubles everywhere&lt;/li&gt;
&lt;li&gt;Slow tests&lt;/li&gt;
&lt;li&gt;Wrong priorities&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Videos and slide decks from the talks&lt;/p&gt;</description>
    </item>
    <item>
      <title>Footgun #3 - The Tests Are Not Isolated</title>
      <link>https://shaigeva.com/posts/10_footguns/03_the_tests_are_not_isolated/</link>
      <pubDate>Tue, 08 Oct 2024 20:15:56 +0300</pubDate>
      <guid>https://shaigeva.com/posts/10_footguns/03_the_tests_are_not_isolated/</guid>
      <description>&lt;p&gt;(this post is part of a &lt;a href=&#34;https://shaigeva.com/posts/10_footguns/ten_footguns/&#34;&gt;series&lt;/a&gt; about good testing practices)&lt;/p&gt;
&lt;p&gt;Writing tests that are not isolated is a sure way to create unnecessary work for ourselves.&lt;/p&gt;
&lt;p&gt;By &amp;ldquo;tests that are not isolated&amp;rdquo;, I mean tests that sometimes have a different outcome (failing / passing) if we run
only a subset of them, if we run them in a different order or if we run them in parallel.&lt;/p&gt;
&lt;h2 id=&#34;why-is-this-a-problem&#34;&gt;Why is this a problem?&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s say we have 30 tests, and test 24 passes if we run it individually but fails if we run the entire test suite.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Footgun #2 - Untested Tests</title>
      <link>https://shaigeva.com/posts/10_footguns/02_untested_tests/</link>
      <pubDate>Sat, 05 Oct 2024 17:15:56 +0300</pubDate>
      <guid>https://shaigeva.com/posts/10_footguns/02_untested_tests/</guid>
      <description>&lt;p&gt;(this post is part of a &lt;a href=&#34;https://shaigeva.com/posts/10_footguns/ten_footguns/&#34;&gt;series&lt;/a&gt; about good testing practices)&lt;/p&gt;
&lt;p&gt;Sometimes our tests lie to us.&lt;/p&gt;
&lt;p&gt;We have a test that was supposed to protect us from some bug, but that bug happened after all.&lt;/p&gt;
&lt;p&gt;Of course, what happened was that we made a mistake, and the test didn&amp;rsquo;t really verify what we thought it does.&lt;/p&gt;
&lt;p&gt;As it turns out - when we write a test, it&amp;rsquo;s a good idea to spend a little effort to verify the test actually works.&lt;br&gt;
To make sure that if the bug happens, the test does indeed fail.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Footgun #1 - There Are No Tests</title>
      <link>https://shaigeva.com/posts/10_footguns/01_there_are_no_tests/</link>
      <pubDate>Fri, 04 Oct 2024 13:01:56 +0300</pubDate>
      <guid>https://shaigeva.com/posts/10_footguns/01_there_are_no_tests/</guid>
      <description>&lt;p&gt;(this post is part of a &lt;a href=&#34;https://shaigeva.com/posts/10_footguns/ten_footguns/&#34;&gt;series&lt;/a&gt; about good testing practices)&lt;/p&gt;
&lt;p&gt;This is a &amp;ldquo;warm-up footgun&amp;rdquo; to the blog post series.&lt;/p&gt;
&lt;p&gt;The easiest way to shoot yourself in the foot, testing-wise, is to have no tests at all.&lt;/p&gt;
&lt;p&gt;In my experience, writing any tests often helps us - even if these tests are not well-written, and even if they&amp;rsquo;re just a drop in the sea.&lt;/p&gt;
&lt;p&gt;There are a few reasons I noticed, why moving from no tests at all to even one test for some area of the code is useful.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
