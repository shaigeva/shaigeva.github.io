<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Footgun #9 - Slow Tests | Shai Geva</title>
<meta name="keywords" content="testing, performance, test-speed, feedback-loop, best-practices">
<meta name="description" content="
This mini-post is part of a series about good testing practices, which I also presented at a couple of conferences.

Here it is in PyCon US 2023


Slow tests are not fun.
In this post, I&rsquo;ll talk about two ways in which they are not fun

The bottleneck and the time bomb
The feedback loop and the bug funnel

The bottleneck and the time bomb

The bottleneck here is where the tests take so long to run, that we have a long queue of tasks waiting to be merged to the main branch.
(this assumes we&rsquo;re merging tasks to the main branch one-by-one, and only after the tests pass. Other branching models have similar issues, but this is the simplest to explain)">
<meta name="author" content="Shai Geva">
<link rel="canonical" href="https://shaigeva.com/posts/10_footguns/09_slow_tests/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.ad7e9ed672bfa63aa62f2a9523f793e89f751a105296a152608bd1ccabf63b08.css" integrity="sha256-rX6e1nK/pjqmLyqVI/eT6J91GhBSlqFSYIvRzKv2Owg=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://shaigeva.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://shaigeva.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://shaigeva.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://shaigeva.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://shaigeva.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://shaigeva.com/posts/10_footguns/09_slow_tests/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-YWC9X8YE9C"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-YWC9X8YE9C');
        }
      </script><meta property="og:url" content="https://shaigeva.com/posts/10_footguns/09_slow_tests/">
  <meta property="og:site_name" content="Shai Geva">
  <meta property="og:title" content="Footgun #9 - Slow Tests">
  <meta property="og:description" content=" This mini-post is part of a series about good testing practices, which I also presented at a couple of conferences. Here it is in PyCon US 2023 Slow tests are not fun.
In this post, I’ll talk about two ways in which they are not fun
The bottleneck and the time bomb The feedback loop and the bug funnel The bottleneck and the time bomb The bottleneck here is where the tests take so long to run, that we have a long queue of tasks waiting to be merged to the main branch.
(this assumes we’re merging tasks to the main branch one-by-one, and only after the tests pass. Other branching models have similar issues, but this is the simplest to explain)">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-05-16T10:18:56+03:00">
    <meta property="article:modified_time" content="2025-05-16T10:18:56+03:00">
    <meta property="article:tag" content="Testing">
    <meta property="article:tag" content="Performance">
    <meta property="article:tag" content="Test-Speed">
    <meta property="article:tag" content="Feedback-Loop">
    <meta property="article:tag" content="Best-Practices">
    <meta property="og:image" content="https://shaigeva.com/10_footguns/10_footguns_09_slow_tests.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://shaigeva.com/10_footguns/10_footguns_09_slow_tests.png">
<meta name="twitter:title" content="Footgun #9 - Slow Tests">
<meta name="twitter:description" content="
This mini-post is part of a series about good testing practices, which I also presented at a couple of conferences.

Here it is in PyCon US 2023


Slow tests are not fun.
In this post, I&rsquo;ll talk about two ways in which they are not fun

The bottleneck and the time bomb
The feedback loop and the bug funnel

The bottleneck and the time bomb

The bottleneck here is where the tests take so long to run, that we have a long queue of tasks waiting to be merged to the main branch.
(this assumes we&rsquo;re merging tasks to the main branch one-by-one, and only after the tests pass. Other branching models have similar issues, but this is the simplest to explain)">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://shaigeva.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Footgun #9 - Slow Tests",
      "item": "https://shaigeva.com/posts/10_footguns/09_slow_tests/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Footgun #9 - Slow Tests",
  "name": "Footgun #9 - Slow Tests",
  "description": " This mini-post is part of a series about good testing practices, which I also presented at a couple of conferences. Here it is in PyCon US 2023 Slow tests are not fun.\nIn this post, I\u0026rsquo;ll talk about two ways in which they are not fun\nThe bottleneck and the time bomb The feedback loop and the bug funnel The bottleneck and the time bomb The bottleneck here is where the tests take so long to run, that we have a long queue of tasks waiting to be merged to the main branch.\n(this assumes we\u0026rsquo;re merging tasks to the main branch one-by-one, and only after the tests pass. Other branching models have similar issues, but this is the simplest to explain)\n",
  "keywords": [
    "testing", "performance", "test-speed", "feedback-loop", "best-practices"
  ],
  "articleBody": " This mini-post is part of a series about good testing practices, which I also presented at a couple of conferences. Here it is in PyCon US 2023 Slow tests are not fun.\nIn this post, I’ll talk about two ways in which they are not fun\nThe bottleneck and the time bomb The feedback loop and the bug funnel The bottleneck and the time bomb The bottleneck here is where the tests take so long to run, that we have a long queue of tasks waiting to be merged to the main branch.\n(this assumes we’re merging tasks to the main branch one-by-one, and only after the tests pass. Other branching models have similar issues, but this is the simplest to explain)\nWhen the tests take too long to run, the merge queue becomes long.\nHow slow is too slow? Assume we have, say, 10 work-hours each day.\n5-minute test suite If the test suite takes 5 minutes to run: That’s 12 merges per hour, or 120 merges a day, before the tests slow us down.\nFor most teams, that virtually never happens, so a 5-minute test suite is not a bottleneck.\n2-hour test suite On the other extreme, and it usually won’t get to that but just so it’s easy to imagine -\nIf the test suite takes 2 hours:\nThat’s only 5 merges per day.\nAnd that’s the best-case scenario: if nobody ever makes a mistake and the tests always pass and the next dev starts running the tests immediately after the previous one finishes.\nIn a case like that, whenever we want to wrap up a bunch of tasks quickly, maybe before a major version, the merge queue length becomes days.\nAnd if people sometimes make mistakes and the tests fail or some manual test takes a bit longer, then we might not be able to even merge 3-4 tasks in a normal day.\nIt just doesn’t work.\nThe team will probably just stop waiting for the tests to pass before merging, and spend a lot of time with the tests being broken.\nNow, we can SURVIVE this way.\nBut it’s a lot of extra work and it’s really not what we want.\nWhere’s the line? Really, this happens with numbers that are far less extreme.\nIn my experience, with a 30 minutes test suite the same things happen.\nLess frequently, but still.\nI would say a good rule of thumb is to aspire to 10 minutes, and never accept more than 20.\nThat time when the bomb exploded A few years ago I was actually part of a team where this happened.\nWhen the tests took 20 minutes, I understood it’s a time bomb and eventually things were going to get bad.\nBut I didn’t have this clear phrasing of exactly how the slowness would be a problem. The bottleneck.\nGranted, at that team we had other problems as well:\nThe tests were a little flaky - sometimes failing randomly. The tests were difficult to debug - to understand why they failed The tests were brittle - small unrelated changes might make them fail (this is different from flakiness, which is random failures). This combo made it so that there was always some failing test that needed urgent fixing, which was “something we could chase”.\nThese urgent fixes masked the slowness problem, because it always seemed like “oh, ok, we just need to stabilize this thing and then it would be ok”.\nAfter a while, we were getting all these problems every few weeks.\nMulti-day merge queues, everything was stuck.\nReal crisis mode.\nIt only became ok after we did an expensive project and made the tests run in parallel.\nTests would still break sometimes, but the queue got back to zero fast enough so it was not a crisis.\nWhat can we do? Make the tests isolated The question is - what do we do about this?\nMeaning, we’re starting a new project (or have an existing project which is not in crisis mode) - what actions should we take to prevent this from happening in the long run?\nWe don’t want premature optimization, so what we need on day 1 is to make sure that WHEN we want to optimize, it’s not going to be a very expensive project.\nAnd specifically, it should be possible to run the tests in parallel because that’s going to be the go-to solution.\nThe only thing we need for that, is to remember the footgun about isolated tests. If the tests don’t affect each other, they can run in parallel, and then the chances of a horrible crisis become much lower.\nSo my advice is to consider test isolation as a must-have.\nThe feedback loop and the bug funnel Another way that slow tests can hurt us is by making our feedback loop longer.\nThe feedback loop is how fast we learn about bugs and understand what happened.\nAnd I’m talking about any type of bug here - anything from a typo to complex concurrency issues.\nThe feedback loop is very important, and anything that makes it shorter is effective.\nEven a squiggly red line in the IDE.\nI usually aim for a setup where most of the time, I’m working in watch-mode, so the tests re-run every time a file changes, and I run a sub-set of the tests that finishes within 2 or 3 seconds.\nNote: This watch-mode setup is for when I'm coding manually.\nWith AI agents, the feedback loop takes a different form, where the AI agent itself should have a feedback loop of its own, but that's a different topic.\nI'm also writing (A LOT) about that. See my post series about AI-first design patterns and frameworks Being fast is easy for the brain Being on the fast side is great.\nFor example, if a test fails just a few seconds after I wrote the code - I instantly understand what’s going on.\nI never got out of context - this code has just been created.\nHowever, with a 10-minute tests suite in CI - the commit with a failing test often contains a lot of code.\nPlus my brain will do a context switch and go catch up on slack.\nSo when I try to understand what’s going on with the failing test - it’s a lot more work.\nBut some tests HAVE to be slow, right? True. For many projects, the reality is that some tests are going to be slow, no matter what we do.\nBut it doesn’t mean hope is lost - we can still have pretty fast feedback loop.\nHow?\nWhat helps me here is that instead of asking “How long does it take for the tests to run” I’m asking “How long does it take to catch a bug”\nAnd I’m visualizing this using the “bug funnel”.\nAll possible theoretical bugs come in, and some of them get filtered out on every stage.\nAnd the key observation here is that we don’t need to catch ALL bugs quickly:\nWe need to catch MOST bugs quickly. The feedback loop needs to be USUALLY fast. To understand why, we’ll look at an example.\nAssume we start out with a bug funnel that looks like this: We only have long-running integration tests, and we only run them in CI.\nLet’s say that during the work on some task, we create 10 bugs.\nThis means that 10 times, we’ll discover that we have a bug only after we commit, push and wait for the CI to run the tests.\nAnd in all 10 times, our debugging is also going to be more difficult because of context switches etc.\nBut what if we add some faster tests?\nLet’s say that, instead, we have this: For the same task with the same 10 bugs - we won’t wait 10 times for the long-running CI. Only for, say, 2 of the bugs.\nFor the rest of the bugs, so most of the time - we’ll have a much faster feedback loop because they would be caught by a faster test.\nNote that we’re still getting the value even if the UTs don’t catch any bug that the integration tests wouldn’t also catch.\nSo while on first thought you might think that the fast unit tests have a bad ROI because they won’t catch more bugs - the reality is different.\nAnd don’t forget:\nTry to run at least some of the tests in watch-mode! You will have a 2-second feedback loop, even if it’s not for everything. As we discussed - you can also use test doubles, that’s why they exist. Conclusion Pay attention to test speed.\nThe CI can’t be too slow, or it becomes a bottleneck.\nAlways make tests isolated to avoid a crisis that can hurt the company.\nAnd try to optimize your feedback loop, even if it only works for a subset of your work.\n\u003c\u003c previous post: Test Doubles Everywhere | next post: Wrong Priorities \u003e\u003e ",
  "wordCount" : "1497",
  "inLanguage": "en",
  "image":"https://shaigeva.com/10_footguns/10_footguns_09_slow_tests.png","datePublished": "2025-05-16T10:18:56+03:00",
  "dateModified": "2025-05-16T10:18:56+03:00",
  "author":{
    "@type": "Person",
    "name": "Shai Geva"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://shaigeva.com/posts/10_footguns/09_slow_tests/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Shai Geva",
    "logo": {
      "@type": "ImageObject",
      "url": "https://shaigeva.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://shaigeva.com/" accesskey="h" title="Shai Geva (Alt + H)">Shai Geva</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://shaigeva.com/about" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://shaigeva.com/talks" title="Talks">
                    <span>Talks</span>
                </a>
            </li>
            <li>
                <a href="https://shaigeva.com/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Footgun #9 - Slow Tests
    </h1>
    <div class="post-meta"><span title='2025-05-16 10:18:56 +0300 IDT'>May 16, 2025</span>&nbsp;·&nbsp;<span>Shai Geva</span>

</div>
  </header> 
<figure class="entry-cover">
        <img loading="eager" src="https://shaigeva.com/10_footguns/10_footguns_09_slow_tests.png" alt="">
        
</figure>
  <div class="post-content"><span class="aside">
This mini-post is part of a <a href="/posts/10_footguns/ten_footguns" target="_blank">series</a> about good testing practices, which I also presented at a couple of conferences.
<br>
Here it is in <a href="https://youtu.be/Ub31Ae6S1BY?t=1099" target="_blank">PyCon US 2023</a>
</span>

<p>Slow tests are not fun.</p>
<p>In this post, I&rsquo;ll talk about two ways in which they are not fun</p>
<ol>
<li>The bottleneck and the time bomb</li>
<li>The feedback loop and the bug funnel</li>
</ol>
<h1 id="the-bottleneck-and-the-time-bomb">The bottleneck and the time bomb<a hidden class="anchor" aria-hidden="true" href="#the-bottleneck-and-the-time-bomb">#</a></h1>
<p><img alt="Bottleneck diagram" loading="lazy" src="/10_footguns/10_footguns_the_bottleneck_and_the_time_bomb.png"></p>
<p>The bottleneck here is where the tests take so long to run, that we have a long queue of tasks waiting to be merged to the main branch.<br>
(this assumes we&rsquo;re merging tasks to the main branch one-by-one, and only after the tests pass. Other branching models have similar issues, but this is the simplest to explain)</p>
<p>When the tests take too long to run, the merge queue becomes long.</p>
<h2 id="how-slow-is-too-slow">How slow is too slow?<a hidden class="anchor" aria-hidden="true" href="#how-slow-is-too-slow">#</a></h2>
<p>Assume we have, say, 10 work-hours each day.</p>
<h3 id="5-minute-test-suite">5-minute test suite<a hidden class="anchor" aria-hidden="true" href="#5-minute-test-suite">#</a></h3>
<p>If the test suite takes 5 minutes to run:
That&rsquo;s 12 merges per hour, or 120 merges a day, before the tests slow us down.<br>
For most teams, that virtually never happens, so a 5-minute test suite is not a bottleneck.</p>
<h3 id="2-hour-test-suite">2-hour test suite<a hidden class="anchor" aria-hidden="true" href="#2-hour-test-suite">#</a></h3>
<p>On the other extreme, and it usually won&rsquo;t get to that but just so it&rsquo;s easy to imagine -<br>
If the test suite takes 2 hours:<br>
That&rsquo;s only 5 merges per day.<br>
And that&rsquo;s the best-case scenario: if nobody ever makes a mistake and the tests always pass and the next dev starts running the tests immediately after the previous one finishes.</p>
<p>In a case like that, whenever we want to wrap up a bunch of tasks quickly, maybe before a major version, the merge queue length becomes days.<br>
And if people sometimes make mistakes and the tests fail or some manual test takes a bit longer, then we might not be able to even merge 3-4 tasks in a normal day.</p>
<p>It just doesn&rsquo;t work.<br>
The team will probably just stop waiting for the tests to pass before merging, and spend a lot of time with the tests being broken.</p>
<p>Now, we can SURVIVE this way.<br>
But it&rsquo;s a lot of extra work and it&rsquo;s really not what we want.</p>
<h3 id="wheres-the-line">Where&rsquo;s the line?<a hidden class="anchor" aria-hidden="true" href="#wheres-the-line">#</a></h3>
<p>Really, this happens with numbers that are far less extreme.<br>
In my experience, with a 30 minutes test suite the same things happen.<br>
Less frequently, but still.</p>
<p>I would say a good rule of thumb is to aspire to 10 minutes, and never accept more than 20.</p>
<h2 id="that-time-when-the-bomb-exploded">That time when the bomb exploded<a hidden class="anchor" aria-hidden="true" href="#that-time-when-the-bomb-exploded">#</a></h2>
<p>A few years ago I was actually part of a team where this happened.</p>
<p>When the tests took 20 minutes, I understood it&rsquo;s a time bomb and eventually things were going to get bad.</p>
<p>But I didn&rsquo;t have this clear phrasing of exactly how the slowness would be a problem. The bottleneck.</p>
<p>Granted, at that team we had other problems as well:</p>
<ul>
<li>The tests were a little flaky - sometimes failing randomly.</li>
<li>The tests were difficult to debug - to understand why they failed</li>
<li>The tests were brittle - small unrelated changes might make them fail (this is different from flakiness, which is random failures).</li>
</ul>
<p>This combo made it so that there was always some failing test that needed urgent fixing, which was &ldquo;something we could chase&rdquo;.<br>
These urgent fixes masked the slowness problem, because it always seemed like &ldquo;oh, ok, we just need to stabilize this thing and then it would be ok&rdquo;.</p>
<p>After a while, we were getting all these problems every few weeks.<br>
Multi-day merge queues, everything was stuck.<br>
Real crisis mode.</p>
<p>It only became ok after we did an expensive project and made the tests run in parallel.<br>
Tests would still break sometimes, but the queue got back to zero fast enough so it was not a crisis.</p>
<h2 id="what-can-we-do-make-the-tests-isolated">What can we do? Make the tests isolated<a hidden class="anchor" aria-hidden="true" href="#what-can-we-do-make-the-tests-isolated">#</a></h2>
<p>The question is - what do we do about this?<br>
Meaning, we&rsquo;re starting a new project (or have an existing project which is not in crisis mode) - what actions should we take to prevent this from happening in the long run?</p>
<p>We don&rsquo;t want premature optimization, so what we need on day 1 is to make sure that WHEN we want to optimize, it&rsquo;s not going to be a very expensive project.</p>
<p>And specifically, it should be possible to run the tests in parallel because that&rsquo;s going to be the go-to solution.</p>
<p>The only thing we need for that, is to remember the footgun about isolated tests.
If the tests don&rsquo;t affect each other, they can run in parallel, and then the chances of a horrible crisis become much lower.</p>
<p>So my advice is to consider test isolation as a must-have.</p>
<h1 id="the-feedback-loop-and-the-bug-funnel">The feedback loop and the bug funnel<a hidden class="anchor" aria-hidden="true" href="#the-feedback-loop-and-the-bug-funnel">#</a></h1>
<p><img alt="Feedback loop and bug funnel diagram" loading="lazy" src="/10_footguns/10_footguns_feedback_loop.png"></p>
<p>Another way that slow tests can hurt us is by making our feedback loop longer.</p>
<p>The feedback loop is how fast we learn about bugs and understand what happened.<br>
And I&rsquo;m talking about any type of bug here - anything from a typo to complex concurrency issues.</p>
<p>The feedback loop is very important, and anything that makes it shorter is effective.<br>
Even a squiggly red line in the IDE.</p>
<p>I usually aim for a setup where most of the time, I&rsquo;m working in <strong>watch-mode</strong>, so the tests re-run every time a file changes, and I run a sub-set of the tests that finishes within 2 or 3 seconds.</p>
<span class="aside">
Note: This watch-mode setup is for when I'm coding manually.<br>
With AI agents, the feedback loop takes a different form, where the AI agent itself should have a feedback loop of its
own, but that's a different topic.<br>
I'm also writing (A LOT) about that. See my post series about
<a href="https://shaigeva.com/posts/ai_frameworks/01_ai_frameworks_intro/" target="_blank">AI-first design patterns and frameworks</a>
</span>

<h2 id="being-fast-is-easy-for-the-brain">Being fast is easy for the brain<a hidden class="anchor" aria-hidden="true" href="#being-fast-is-easy-for-the-brain">#</a></h2>
<p>Being on the fast side is great.<br>
For example, if a test fails just a few seconds after I wrote the code - I instantly understand what&rsquo;s going on.<br>
I never got out of context - this code has just been created.</p>
<p>However, with a 10-minute tests suite in CI - the commit with a failing test often contains a lot of code.<br>
Plus my brain will do a context switch and go catch up on slack.<br>
So when I try to understand what&rsquo;s going on with the failing test - it&rsquo;s a lot more work.</p>
<h2 id="but-some-tests-have-to-be-slow-right">But some tests HAVE to be slow, right?<a hidden class="anchor" aria-hidden="true" href="#but-some-tests-have-to-be-slow-right">#</a></h2>
<p>True. For many projects, the reality is that some tests are going to be slow, no matter what we do.<br>
But it doesn&rsquo;t mean hope is lost - we can still have pretty fast feedback loop.</p>
<p>How?<br>
What helps me here is that instead of asking
&ldquo;How long does it take for the tests to run&rdquo;
I&rsquo;m asking
&ldquo;How long does it take to catch a bug&rdquo;</p>
<p>And I&rsquo;m visualizing this using the &ldquo;bug funnel&rdquo;.</p>
<p><img alt="Bug funnel diagram" loading="lazy" src="/10_footguns/10_footguns_the_bug_funnel.png"></p>
<p>All possible theoretical bugs come in, and some of them get filtered out on every stage.</p>
<p>And the key observation here is that we don&rsquo;t need to catch ALL bugs quickly:</p>
<ul>
<li>We need to catch MOST bugs quickly.</li>
<li>The feedback loop needs to be USUALLY fast.</li>
</ul>
<p>To understand why, we&rsquo;ll look at an example.<br>
Assume we start out with a bug funnel that looks like this:
<img alt="Bug funnel with only CI integration tests" loading="lazy" src="/10_footguns/10_footguns_bug_funnel_with_only_ci_integration_tests.png"></p>
<p>We only have long-running integration tests, and we only run them in CI.</p>
<p>Let&rsquo;s say that during the work on some task, we create 10 bugs.<br>
This means that 10 times, we&rsquo;ll discover that we have a bug only after we commit, push and wait for the CI to run the
tests.<br>
And in all 10 times, our debugging is also going to be more difficult because of context switches etc.</p>
<p>But what if we add some faster tests?<br>
Let&rsquo;s say that, instead, we have this:
<img alt="Bug funnel with multiple test layers" loading="lazy" src="/10_footguns/10_footguns_bug_funnel_with_multiple_test_layers.png"></p>
<p>For the same task with the same 10 bugs - we won&rsquo;t wait 10 times for the long-running CI. Only for, say, 2 of the bugs.<br>
For the rest of the bugs, so most of the time - we&rsquo;ll have a much faster feedback loop because they would be caught by
a faster test.</p>
<p>Note that we&rsquo;re still getting the value even if the UTs don&rsquo;t catch any bug that the integration tests wouldn&rsquo;t also
catch.<br>
So while on first thought you might think that the fast unit tests have a bad ROI because they won&rsquo;t catch more bugs -
the reality is different.</p>
<p>And don&rsquo;t forget:</p>
<ul>
<li>Try to run at least some of the tests in watch-mode!
You will have a 2-second feedback loop, even if it&rsquo;s not for everything.</li>
<li>As we discussed - you can also use test doubles, that&rsquo;s why they exist.</li>
</ul>
<h2 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h2>
<p>Pay attention to test speed.</p>
<p>The CI can&rsquo;t be too slow, or it becomes a bottleneck.<br>
Always make tests isolated to avoid a crisis that can hurt the company.</p>
<p>And try to optimize your feedback loop, even if it only works for a subset of your work.</p>
<hr>

<div style="text-align: center; display: block; width: 100%;">
<a href="/posts/10_footguns/08_test_doubles_everywhere">&lt;&lt; previous post: Test Doubles Everywhere</a>
|
<a href="/posts/10_footguns/10_wrong_priorities">next post: Wrong Priorities &gt;&gt;
</div>



  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://shaigeva.com/tags/testing/">Testing</a></li>
      <li><a href="https://shaigeva.com/tags/performance/">Performance</a></li>
      <li><a href="https://shaigeva.com/tags/test-speed/">Test-Speed</a></li>
      <li><a href="https://shaigeva.com/tags/feedback-loop/">Feedback-Loop</a></li>
      <li><a href="https://shaigeva.com/tags/best-practices/">Best-Practices</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://shaigeva.com/">Shai Geva</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
