<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>In Search of Production-Grade Maintainable AI-First Development: AI-First frameworks (blog post series) | Shai Geva</title>
<meta name="keywords" content="">
<meta name="description" content="(this is the first post in a series about creating production-grade maintainable AI-first projects, using AI-first frameworks)
Like many others, I spent a lot of time thinking about AI and software development.
I belong to the camp that believes that AI is a total paradigm shift - it&rsquo;ll redefine the ecosystem and what it means to
create software, and it&rsquo;ll be the deepest change we have seen to date.
My own &ldquo;flavor&rdquo; of thinking about this is to try, from an engineering / implementation perspective, to understand
what that change could look like.
Figure out what are the technical &ldquo;bottlenecks&rdquo; and what would move the needle on them.
Are LLMs a limiting factor? Do the LLMs have to be essentially smarter than they are today for this to happen?
Do we need to create some specific tooling?
Disallow use of some tooling? Maybe a specific workflow?">
<meta name="author" content="Shai Geva">
<link rel="canonical" href="https://shaigeva.com/posts/ai_frameworks/01_ai_frameworks_intro/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css" integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://shaigeva.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://shaigeva.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://shaigeva.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://shaigeva.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://shaigeva.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://shaigeva.com/posts/ai_frameworks/01_ai_frameworks_intro/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-YWC9X8YE9C"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-YWC9X8YE9C');
        }
      </script><meta property="og:title" content="In Search of Production-Grade Maintainable AI-First Development: AI-First frameworks (blog post series)" />
<meta property="og:description" content="(this is the first post in a series about creating production-grade maintainable AI-first projects, using AI-first frameworks)
Like many others, I spent a lot of time thinking about AI and software development.
I belong to the camp that believes that AI is a total paradigm shift - it&rsquo;ll redefine the ecosystem and what it means to
create software, and it&rsquo;ll be the deepest change we have seen to date.
My own &ldquo;flavor&rdquo; of thinking about this is to try, from an engineering / implementation perspective, to understand
what that change could look like.
Figure out what are the technical &ldquo;bottlenecks&rdquo; and what would move the needle on them.
Are LLMs a limiting factor? Do the LLMs have to be essentially smarter than they are today for this to happen?
Do we need to create some specific tooling?
Disallow use of some tooling? Maybe a specific workflow?" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://shaigeva.com/posts/ai_frameworks/01_ai_frameworks_intro/" />
<meta property="og:image" content="https://shaigeva.com/ai_frameworks/ai_feedback_loop_1-min.png" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-05-10T13:01:56+03:00" />
<meta property="article:modified_time" content="2025-05-10T13:01:56+03:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://shaigeva.com/ai_frameworks/ai_feedback_loop_1-min.png" />
<meta name="twitter:title" content="In Search of Production-Grade Maintainable AI-First Development: AI-First frameworks (blog post series)"/>
<meta name="twitter:description" content="(this is the first post in a series about creating production-grade maintainable AI-first projects, using AI-first frameworks)
Like many others, I spent a lot of time thinking about AI and software development.
I belong to the camp that believes that AI is a total paradigm shift - it&rsquo;ll redefine the ecosystem and what it means to
create software, and it&rsquo;ll be the deepest change we have seen to date.
My own &ldquo;flavor&rdquo; of thinking about this is to try, from an engineering / implementation perspective, to understand
what that change could look like.
Figure out what are the technical &ldquo;bottlenecks&rdquo; and what would move the needle on them.
Are LLMs a limiting factor? Do the LLMs have to be essentially smarter than they are today for this to happen?
Do we need to create some specific tooling?
Disallow use of some tooling? Maybe a specific workflow?"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://shaigeva.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "In Search of Production-Grade Maintainable AI-First Development: AI-First frameworks (blog post series)",
      "item": "https://shaigeva.com/posts/ai_frameworks/01_ai_frameworks_intro/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "In Search of Production-Grade Maintainable AI-First Development: AI-First frameworks (blog post series)",
  "name": "In Search of Production-Grade Maintainable AI-First Development: AI-First frameworks (blog post series)",
  "description": "(this is the first post in a series about creating production-grade maintainable AI-first projects, using AI-first frameworks)\nLike many others, I spent a lot of time thinking about AI and software development.\nI belong to the camp that believes that AI is a total paradigm shift - it\u0026rsquo;ll redefine the ecosystem and what it means to create software, and it\u0026rsquo;ll be the deepest change we have seen to date.\nMy own \u0026ldquo;flavor\u0026rdquo; of thinking about this is to try, from an engineering / implementation perspective, to understand what that change could look like.\nFigure out what are the technical \u0026ldquo;bottlenecks\u0026rdquo; and what would move the needle on them.\nAre LLMs a limiting factor? Do the LLMs have to be essentially smarter than they are today for this to happen?\nDo we need to create some specific tooling?\nDisallow use of some tooling? Maybe a specific workflow?\n",
  "keywords": [
    
  ],
  "articleBody": "(this is the first post in a series about creating production-grade maintainable AI-first projects, using AI-first frameworks)\nLike many others, I spent a lot of time thinking about AI and software development.\nI belong to the camp that believes that AI is a total paradigm shift - it’ll redefine the ecosystem and what it means to create software, and it’ll be the deepest change we have seen to date.\nMy own “flavor” of thinking about this is to try, from an engineering / implementation perspective, to understand what that change could look like.\nFigure out what are the technical “bottlenecks” and what would move the needle on them.\nAre LLMs a limiting factor? Do the LLMs have to be essentially smarter than they are today for this to happen?\nDo we need to create some specific tooling?\nDisallow use of some tooling? Maybe a specific workflow?\nCreating maintainable software I think it’s clear by now (2025-06), that coding agents can help us in many ways, including creating impressive projects to a level that would seem science fiction just a few years ago.\nWe’re seeing fast and significant improvement in many areas of dev work.\nOne of the main areas that still didn’t see a major breakthrough is coding in large codebases, which is the bulk of dev work today.\nI’m sure there are exceptions here and there, but as a general rule, you still can’t tell you AI tool to add a feature to a million-line code base, and it’ll do most of the work.\nIn practice this just doesn’t work ATM.\nFrameworks are the easy path I’ve come to the conclusion that the way forward goes through something I think of as AI-first frameworks, and AI agents that use these frameworks to develop software.\nVery loosely, what I mean by a framework is “definitions that dictate important aspects of the code and workflow”.\nThis can include things like tech stack, packages, tooling, coding conventions, code design, testing conventions, etc. etc.\nThe central point here is that we will not continue to write code like we do now. The specifications, design, coding practices, testing and workflows will change.\nAnd I think that change will be substantial.\nThe main reason I believe this will happen is that any way I look at it, the current common practices will simply make it very hard to implement some of the most important improvements that are coming.\nThe easiest way to make AI much more productive is to build the software in a way that “fits” the AI from the ground up.\nHaving each team develop their own AI-compatible practices for their code base is kind of like having each backend team develop their own web framework from low-level http libraries.\nIt can be done, but we all understand it’s not a good idea. It’s very expensive and will likely not turn out well. A model where there are common (open source?) frameworks / tools, and most teams just use a combination of a few standard options, is probably much better.\nA blog series about AI-coding implementation In this series of posts, I will try to show in detail why I believe this and what kind of changes I think we can expect.\nThere will be a bit of high-level exploration, but mostly - we’ll dive into concrete, low-level examples: discussing specific ideas / practices that can make AI more productive if they are enforced.\nMost (or all) concepts are not going to be too exotic - the approaches we’ll explore are all existing industry techniques, taken from various fields.\nAn experienced developer will be familiar with many of them.\nThe point here is not to invent crazy new ideas, but to examine the option of applying what already exists in an organized way to the general problem of programming with AI.\nI’ll try to set up small POCs to show that things are realistic in places where it’s more difficult to see (I’m not planning full implementation of a framework or agent).\nTL;DR There are a lot of pieces to this, and it’ll take many weeks until I manage to release blog posts covering everything I have in mind, so it’s worth it to give a very high level view of the approach here:\nPrinciples: Code that AI creates is expected to be different than what a human team would create. AI agents and human teams have different tradeoffs when it comes to productivity ROI. The central notion that I’ll discuss is the ability to have an internal AI feedback loop (plan-do-verify) that allows the AI to self-heal most errors. I will argue that “plan” and “do” can be greatly improved by enforcing some standards - things like “attach English documentation to many things” or “use static typing more robustly in specific ways”. That is, however, the smaller part of the series. The main focus will be on “verify” - allowing the AI to check the changes it makes. I will argue that “adding on quality” on artibrary code bases is very difficult compared to an approach that structures the code base specifically so that AI will be able to verify it. And I’ll give a bunch of examples of practices that make an effective feedback loop far easier, and some arguments to show why this is more difficult in arbitrary code bases. My hope is that these blog posts will help a little in making this critical perspective a central part of the AI-implemetation discussion. Implementation. I’ll explore ways that these approaches can be used in a framework.\nThe main technical requirement is to be able to “rule-out” as many “bugs” as possible, as quickly as possible. “Quick” means that almost all “bugs” can be ruled-out in a few seconds by the AI without human intervention.\nThere will, of course, also be slower verifications like e2e tests - but most bugs should be caught by the faster tests, earlier in the process.\nThis has very strong implications on what practices are expected to be effective.\nFor instance:\nWe need a setup where the AI agent can run code to check what it does (sometimes the entire program, sometiems only tests). Having an LLM just “review” written code just ain’t gonna cut it. But - we should try hard to verify things about the code even without running it (as a test or otherwise). Examples: Static typing, of course. This can be taken further than most people are aware and AI is a good match for this. Preference for pure functions where applicable. Have simulators for most side-effects, especially those that we don’t directly control. AKA “fakes” in standard test-speak. Required because side-effects might be unsafe, unreliable, uncontrollable and slow, but we must allow the AI to run code (either as a test or not) in a way that is safe-enough, reliable-enough, controllable-enough and fast-enough. This is an almost logical necessity, even though it’s not “part of the conversation” now at all (I’m not sure I’ve ever seen it mentioned in the AI-building conversation, actually). Without this, everything’s going to be much harder. I will be talking a lot about this, since bringing this down to reality is expected to be a challenge. Very strong preference towards small building blocks that compose into larger components where possible (stronger than would be appropriated for most human teams). This helps to have “divide and conquer” of bugs, leaving as few bugs as possible to the more complex, slower tests. Lastly, of course - we need to actually use all of this to design and create coding+testing strategies that have a good ROI for the AI. This point is the most vague, the most nuanced, but also probably the most important because it’s necessary, and I think it’s pretty difficult. I’ve had these ideas running around in my head for while and at least for me they are interesting, so I felt like it’s time to share.\nI hope you find this interesting as well and that it’ll spark some discussion :)\nPing me on social and let me know!\nNext post: First feedback loop example? (high level)\nnext post: First feedback loop example \u003e\u003e ",
  "wordCount" : "1359",
  "inLanguage": "en",
  "image":"https://shaigeva.com/ai_frameworks/ai_feedback_loop_1-min.png","datePublished": "2025-05-10T13:01:56+03:00",
  "dateModified": "2025-05-10T13:01:56+03:00",
  "author":{
    "@type": "Person",
    "name": "Shai Geva"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://shaigeva.com/posts/ai_frameworks/01_ai_frameworks_intro/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Shai Geva",
    "logo": {
      "@type": "ImageObject",
      "url": "https://shaigeva.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://shaigeva.com/" accesskey="h" title="Shai Geva (Alt + H)">Shai Geva</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://shaigeva.com/about" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://shaigeva.com/talks" title="Talks">
                    <span>Talks</span>
                </a>
            </li>
            <li>
                <a href="https://shaigeva.com/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      In Search of Production-Grade Maintainable AI-First Development: AI-First frameworks (blog post series)
    </h1>
    <div class="post-meta"><span title='2025-05-10 13:01:56 +0300 IDT'>May 10, 2025</span>&nbsp;·&nbsp;Shai Geva

</div>
  </header> 
<figure class="entry-cover"><img loading="eager" src="https://shaigeva.com/ai_frameworks/ai_feedback_loop_1-min.png" alt="">
        
</figure>
  <div class="post-content"><p>(this is the first post in a series about creating production-grade maintainable AI-first projects, using AI-first frameworks)</p>
<p>Like many others, I spent a lot of time thinking about AI and software development.</p>
<p>I belong to the camp that believes that AI is a total paradigm shift - it&rsquo;ll redefine the ecosystem and what it means to
create software, and it&rsquo;ll be the deepest change we have seen to date.</p>
<p>My own &ldquo;flavor&rdquo; of thinking about this is to try, from an <strong>engineering / implementation</strong> perspective, to understand
what that change could look like.<br>
Figure out what are the technical &ldquo;bottlenecks&rdquo; and what would move the needle on them.<br>
Are LLMs a limiting factor? Do the LLMs have to be essentially smarter than they are today for this to happen?<br>
Do we need to create some specific tooling?<br>
Disallow use of some tooling? Maybe a specific workflow?</p>
<h2 id="creating-maintainable-software">Creating maintainable software<a hidden class="anchor" aria-hidden="true" href="#creating-maintainable-software">#</a></h2>
<p>I think it&rsquo;s clear by now (2025-06), that coding agents can help us in many ways, including creating impressive projects
to a level that would seem science fiction just a few years ago.<br>
We&rsquo;re seeing fast and significant improvement in many areas of dev work.</p>
<p>One of the main areas that still didn&rsquo;t see a major breakthrough is coding in large codebases, which is the bulk of
dev work today.<br>
I&rsquo;m sure there are exceptions here and there, but as a general rule, you still can&rsquo;t tell you AI tool to add a feature
to a million-line code base, and it&rsquo;ll do most of the work.<br>
In practice this just doesn&rsquo;t work ATM.</p>
<h2 id="frameworks-are-the-easy-path">Frameworks are the easy path<a hidden class="anchor" aria-hidden="true" href="#frameworks-are-the-easy-path">#</a></h2>
<p>I&rsquo;ve come to the conclusion that the way forward goes through something I think of as <strong>AI-first frameworks</strong>, and
AI agents that use these frameworks to develop software.</p>
<p>Very loosely, what I mean by a framework is &ldquo;definitions that dictate important aspects of the code and workflow&rdquo;.<br>
This can include things like tech stack, packages, tooling, coding conventions, code design, testing conventions, etc. etc.<br>
The central point here is that we will not continue to write code like we do now. The specifications, design, coding
practices, testing and workflows will change.<br>
And I think that change will be substantial.</p>
<p>The main reason I believe this will happen is that any way I look at it, the current common practices will simply make
it very hard to implement some of the most important improvements that are coming.<br>
The easiest way to make AI much more productive is to build the software in a way that &ldquo;fits&rdquo; the AI from the ground up.</p>
<p>Having each team develop their own AI-compatible practices for their code base is kind of like having each backend team
develop their own web framework from low-level http libraries.<br>
It can be done, but we all understand it&rsquo;s not a good idea. It&rsquo;s very expensive and will likely not turn out well. A
model where there are common (open source?)
frameworks / tools, and most teams just use a combination of a few standard options, is probably much better.</p>
<h2 id="a-blog-series-about-ai-coding-implementation">A blog series about AI-coding implementation<a hidden class="anchor" aria-hidden="true" href="#a-blog-series-about-ai-coding-implementation">#</a></h2>
<p>In this series of posts, I will try to show in detail why I believe this and what kind of changes I think we can expect.</p>
<p>There will be a bit of high-level exploration, but mostly - we&rsquo;ll dive into concrete, low-level examples: discussing
specific ideas / practices that can make AI more productive if they are enforced.</p>
<p>Most (or all) concepts are not going to be too exotic - the approaches we&rsquo;ll explore are all existing industry
techniques, taken from various fields.<br>
An experienced developer will be familiar with many of them.<br>
The point here is not to invent crazy new ideas, but to examine the option of applying what already exists in an
organized way to the general problem of programming with AI.</p>
<p>I&rsquo;ll try to set up small POCs to show that things are realistic in places where it&rsquo;s more difficult to see (I&rsquo;m not
planning full implementation of a framework or agent).</p>
<h2 id="tldr">TL;DR<a hidden class="anchor" aria-hidden="true" href="#tldr">#</a></h2>
<p>There are a lot of pieces to this, and it&rsquo;ll take many weeks until I manage to release blog posts covering everything I
have in mind, so it&rsquo;s worth it to give a very high level view of the approach here:</p>
<h3 id="principles">Principles:<a hidden class="anchor" aria-hidden="true" href="#principles">#</a></h3>
<ol>
<li>Code that AI creates is expected to be different than what a human team would create. AI agents and human teams have
different tradeoffs when it comes to productivity ROI.</li>
<li>The central notion that I&rsquo;ll discuss is the ability to have an internal AI feedback loop (plan-do-verify) that allows
the AI to self-heal most errors.</li>
<li>I will argue that &ldquo;plan&rdquo; and &ldquo;do&rdquo; can be greatly improved by enforcing some standards - things like &ldquo;attach English
documentation to many things&rdquo; or &ldquo;use static typing more robustly in specific ways&rdquo;. That is, however, the smaller part
of the series.</li>
<li>The main focus will be on &ldquo;verify&rdquo; - allowing the AI to check the changes it makes.</li>
<li>I will argue that &ldquo;adding on quality&rdquo; on artibrary code bases is very difficult compared to an approach that
structures the code base specifically so that AI will be able to verify it.</li>
<li>And I&rsquo;ll give a bunch of examples of practices that make an effective feedback loop far easier, and some arguments to
show why this is more difficult in arbitrary code bases.</li>
<li>My hope is that these blog posts will help a little in making this critical perspective a central part of the
AI-implemetation discussion.</li>
</ol>
<h3 id="implementation">Implementation.<a hidden class="anchor" aria-hidden="true" href="#implementation">#</a></h3>
<p>I&rsquo;ll explore ways that these approaches can be used in a framework.<br>
The main technical requirement is to be able to &ldquo;rule-out&rdquo; as many &ldquo;bugs&rdquo; as possible, as quickly as possible. &ldquo;Quick&rdquo;
means that almost all &ldquo;bugs&rdquo; can be ruled-out in a few seconds by the AI without human intervention.<br>
There will, of course, also be slower verifications like e2e tests - but most bugs should be caught by the faster tests,
earlier in the process.</p>
<p>This has very strong implications on what practices are expected to be effective.<br>
For instance:</p>
<ol>
<li>We need a setup where the AI agent can run code to check what it does (sometimes the entire program, sometiems only
tests). Having an LLM just &ldquo;review&rdquo; written code just ain&rsquo;t gonna cut it.</li>
<li>But - we should try hard to verify things about the code even without running it (as a test or otherwise). Examples:
<ol>
<li>Static typing, of course. This can be taken further than most people are aware and AI is a good match for this.</li>
<li>Preference for pure functions where applicable.</li>
</ol>
</li>
<li>Have simulators for most side-effects, especially those that we don&rsquo;t directly control.
<ol>
<li>AKA &ldquo;fakes&rdquo; in standard test-speak.</li>
<li>Required because side-effects might be unsafe, unreliable, uncontrollable and slow, but we must allow the AI to
run code (either as a test or not) in a way that is safe-enough, reliable-enough, controllable-enough and
fast-enough.</li>
<li>This is an almost logical necessity, even though it&rsquo;s not &ldquo;part of the conversation&rdquo; now at all (I&rsquo;m not sure
I&rsquo;ve ever seen it mentioned in the AI-building conversation, actually). Without this, everything&rsquo;s going to be much
harder.</li>
<li>I will be talking a lot about this, since bringing this down to reality is expected to be a challenge.</li>
</ol>
</li>
<li>Very strong preference towards small building blocks that compose into larger components where possible (stronger
than would be appropriated for most human teams). This helps to have &ldquo;divide and conquer&rdquo; of bugs, leaving as
few bugs as possible to the more complex, slower tests.</li>
<li>Lastly, of course - we need to actually use all of this to design and create coding+testing strategies that have a
good ROI for the AI. This point is the most vague, the most nuanced, but also probably the most important because it&rsquo;s
necessary, and I think it&rsquo;s pretty difficult.</li>
</ol>
<hr>
<p>I&rsquo;ve had these ideas running around in my head for while and at least for me they are interesting, so I felt like
it&rsquo;s time to share.<br>
I hope you find this interesting as well and that it&rsquo;ll spark some discussion :)<br>
Ping me on social and let me know!</p>
<p><strong>Next post</strong>: <a href="/posts/ai_frameworks/02_first_feedback_loop_example/">First feedback loop example?</a> (high level)</p>
<hr>

<div style="text-align: center; display: block; width: 100%;">
<a href="/posts/ai_frameworks/02_first_feedback_loop_example">next post: First feedback loop example &gt;&gt;</a>
</div>



  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://shaigeva.com/">Shai Geva</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
