<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Feedback-Loop on Shai Geva</title>
    <link>https://shaigeva.com/tags/feedback-loop/</link>
    <description>Recent content in Feedback-Loop on Shai Geva</description>
    <generator>Hugo -- 0.151.0</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 04 Oct 2025 13:01:56 +0300</lastBuildDate>
    <atom:link href="https://shaigeva.com/tags/feedback-loop/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>What an AI Feedback Loop Looks Like</title>
      <link>https://shaigeva.com/posts/ai_frameworks/02_ai_feedback_loop_example/</link>
      <pubDate>Sat, 04 Oct 2025 13:01:56 +0300</pubDate>
      <guid>https://shaigeva.com/posts/ai_frameworks/02_ai_feedback_loop_example/</guid>
      <description>&lt;span class=&#34;aside&#34;&gt;
this post is part of a &lt;a href=&#34;https://shaigeva.com/posts/ai_frameworks/01_ai_frameworks_intro&#34; target=&#34;_blank&#34;&gt;series&lt;/a&gt; about creating
production-grade maintainable AI-first projects, using AI-first design patterns and frameworks.
&lt;/span&gt;

&lt;p&gt;In the previous post I mentioned that an internal AI feedback loop will be central to all our AI-first design patterns.&lt;/p&gt;
&lt;p&gt;But &amp;ldquo;AI feedback loop&amp;rdquo; might mean different things to different people - so this lightweight post focuses on
giving an example to make it concrete.&lt;/p&gt;
&lt;p&gt;We will implement a small (but realistic) project.&lt;br&gt;
The project is set up so the agent has an internal feedback loop - it has instructions that tell
it to use a loop, and it has a clear way to create effective tests and run validations (the tests it creates,
type-checking, linter).&lt;br&gt;
We&amp;rsquo;ll see how it makes mistakes, finds them and self-heals.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Footgun #9 - Slow Tests</title>
      <link>https://shaigeva.com/posts/10_footguns/09_slow_tests/</link>
      <pubDate>Fri, 16 May 2025 10:18:56 +0300</pubDate>
      <guid>https://shaigeva.com/posts/10_footguns/09_slow_tests/</guid>
      <description>&lt;span class=&#34;aside&#34;&gt;
This mini-post is part of a &lt;a href=&#34;https://shaigeva.com/posts/10_footguns/ten_footguns&#34; target=&#34;_blank&#34;&gt;series&lt;/a&gt; about good testing practices, which I also presented at a couple of conferences.
&lt;br&gt;
Here it is in &lt;a href=&#34;https://youtu.be/Ub31Ae6S1BY?t=1099&#34; target=&#34;_blank&#34;&gt;PyCon US 2023&lt;/a&gt;
&lt;/span&gt;

&lt;p&gt;Slow tests are not fun.&lt;/p&gt;
&lt;p&gt;In this post, I&amp;rsquo;ll talk about two ways in which they are not fun&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The bottleneck and the time bomb&lt;/li&gt;
&lt;li&gt;The feedback loop and the bug funnel&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;the-bottleneck-and-the-time-bomb&#34;&gt;The bottleneck and the time bomb&lt;/h1&gt;
&lt;p&gt;&lt;img alt=&#34;Bottleneck diagram&#34; loading=&#34;lazy&#34; src=&#34;https://shaigeva.com/10_footguns/10_footguns_the_bottleneck_and_the_time_bomb.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;The bottleneck here is where the tests take so long to run, that we have a long queue of tasks waiting to be merged to the main branch.&lt;br&gt;
(this assumes we&amp;rsquo;re merging tasks to the main branch one-by-one, and only after the tests pass. Other branching models have similar issues, but this is the simplest to explain)&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
